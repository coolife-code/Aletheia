"""
Aletheia - AIèˆ†æƒ…è°è¨€é‰´å®šç³»ç»Ÿ
Gradioç‰ˆæœ¬ä¸»å…¥å£æ–‡ä»¶
éƒ¨ç½²åˆ°é­”æ­ç¤¾åŒºåˆ›ç©ºé—´
"""

import os
import sys
import asyncio
import json
from typing import AsyncGenerator

# å°†backendæ·»åŠ åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))

import gradio as gr
from app.agents.parser import ParserAgent
from app.agents.search import SearchAgent
from app.agents.verdict import VerdictAgent

# åˆå§‹åŒ–Agents
parser_agent = ParserAgent()
search_agent = SearchAgent()
verdict_agent = VerdictAgent()


def get_conclusion_emoji(conclusion: str) -> str:
    """æ ¹æ®ç»“è®ºç±»å‹è¿”å›å¯¹åº”çš„emoji"""
    return {
        "true": "âœ…",
        "false": "âŒ",
        "uncertain": "âš ï¸",
        "unverifiable": "â“",
        "partially_true": "ğŸŸ¨",
        "misleading": "ğŸŸ§"
    }.get(conclusion, "â“")


def get_conclusion_label(conclusion: str) -> str:
    """æ ¹æ®ç»“è®ºç±»å‹è¿”å›ä¸­æ–‡æ ‡ç­¾"""
    return {
        "true": "çœŸå®",
        "false": "è™šå‡",
        "uncertain": "å­˜ç–‘",
        "unverifiable": "æ— æ³•æ ¸å®",
        "partially_true": "éƒ¨åˆ†çœŸå®",
        "misleading": "è¯¯å¯¼æ€§"
    }.get(conclusion, "æœªçŸ¥")


async def verify_content_stream(content: str):
    """
    æµå¼é‰´å®šèˆ†æƒ…å†…å®¹ï¼Œå®æ—¶è¿”å›æ¯ä¸ªAgentçš„æ¨ç†è¿‡ç¨‹
    """
    if not content or not content.strip():
        yield "è¯·è¾“å…¥éœ€è¦é‰´å®šçš„èˆ†æƒ…å†…å®¹", "", "", ""
        return

    reasoning_text = ""
    result_text = ""
    evidence_text = ""

    try:
        # ==================== Step 1: Parser Agent ====================
        reasoning_text += "## ğŸ” Parser Agent - é—®é¢˜åˆ†æ\n\n"
        yield reasoning_text, result_text, evidence_text, "æ­£åœ¨åˆ†æé—®é¢˜..."

        parser_result_data = None
        async for parser_event in parser_agent.parse_stream(content):
            event_type = parser_event.get("type")
            step = parser_event.get("step", "")
            event_content = parser_event.get("content", "")

            if event_type == "reasoning":
                reasoning_text += f"**{step}**: {event_content}\n\n"
                yield reasoning_text, result_text, evidence_text, f"Parser: {step}..."
            elif event_type == "result":
                parser_result_data = parser_event.get("data")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¾„æ¸…
        if parser_result_data and parser_result_data.get("needs_clarification"):
            clarification = parser_result_data.get("clarification_prompt", "è¯·æä¾›æ›´å¤šå…·ä½“ä¿¡æ¯")
            result_text = f"## âš ï¸ éœ€è¦è¡¥å……ä¿¡æ¯\n\n{clarification}"
            yield reasoning_text, result_text, evidence_text, "éœ€è¦è¡¥å……ä¿¡æ¯"
            return

        if not parser_result_data:
            result_text = "## âŒ è§£æå¤±è´¥\n\næ— æ³•è§£æè¾“å…¥å†…å®¹ï¼Œè¯·é‡è¯•ã€‚"
            yield reasoning_text, result_text, evidence_text, "è§£æå¤±è´¥"
            return

        # ==================== Step 2: Search Agent ====================
        reasoning_text += "\n---\n\n## ğŸ” Search Agent - æ·±åº¦æœç´¢\n\n"
        yield reasoning_text, result_text, evidence_text, "æ­£åœ¨æœç´¢ç›¸å…³ä¿¡æ¯..."

        search_result_data = None
        async for search_event in search_agent.search_stream(parser_result_data, content):
            event_type = search_event.get("type")
            step = search_event.get("step", "")
            event_content = search_event.get("content", "")

            if event_type == "reasoning":
                reasoning_text += f"**{step}**: {event_content}\n\n"
                yield reasoning_text, result_text, evidence_text, f"Search: {step}..."
            elif event_type == "result":
                search_result_data = search_event.get("data")

        if not search_result_data:
            result_text = "## âŒ æœç´¢å¤±è´¥\n\næ— æ³•è·å–ç›¸å…³ä¿¡æ¯ï¼Œè¯·é‡è¯•ã€‚"
            yield reasoning_text, result_text, evidence_text, "æœç´¢å¤±è´¥"
            return

        # ==================== Step 3: Verdict Agent ====================
        reasoning_text += "\n---\n\n## ğŸ¯ Verdict Agent - å¤šç»´åº¦é‰´å®š\n\n"
        yield reasoning_text, result_text, evidence_text, "æ­£åœ¨è¿›è¡Œå¤šç»´åº¦é‰´å®š..."

        verdict_result_data = None
        async for verdict_event in verdict_agent.verdict_stream(search_result_data, content):
            event_type = verdict_event.get("type")
            step = verdict_event.get("step", "")
            event_content = verdict_event.get("content", "")

            if event_type == "reasoning":
                reasoning_text += f"**{step}**: {event_content}\n\n"
                yield reasoning_text, result_text, evidence_text, f"Verdict: {step}..."
            elif event_type == "result":
                verdict_result_data = verdict_event.get("data")

        # ==================== æœ€ç»ˆç»“æœ ====================
        if verdict_result_data:
            conclusion = verdict_result_data.get("conclusion", "uncertain")
            confidence = verdict_result_data.get("confidence_score", 0.5)
            summary = verdict_result_data.get("conclusion_summary", "")

            emoji = get_conclusion_emoji(conclusion)
            label = get_conclusion_label(conclusion)

            # æ„å»ºç»“æœå±•ç¤º
            result_text = f"""## {emoji} é‰´å®šç»“è®º: {label}

**ç½®ä¿¡åº¦**: {confidence:.0%}

### ç»“è®ºæ‘˜è¦
{summary}

### å¤šç»´åº¦åˆ†æ
"""

            # æ·»åŠ å¤šç»´åº¦åˆ†æ
            dimensional = verdict_result_data.get("dimensional_analysis", {})
            for dim_name, dim_data in dimensional.items():
                dim_labels = {
                    "factual": "ğŸ“Š äº‹å®ç»´åº¦",
                    "contextual": "ğŸ“‹ èƒŒæ™¯ç»´åº¦",
                    "motivational": "ğŸ’­ åŠ¨æœºç»´åº¦",
                    "impact": "ğŸŒŸ å½±å“ç»´åº¦"
                }
                label_text = dim_labels.get(dim_name, dim_name)
                analysis = dim_data.get("analysis", "")[:200]
                conf = dim_data.get("confidence", 0.5)
                result_text += f"\n**{label_text}**: {analysis} (ç½®ä¿¡åº¦: {conf:.0%})\n"

            # æ·»åŠ å‘ç°åˆ†ç±»
            findings = verdict_result_data.get("findings", {})
            result_text += f"""
### å‘ç°åˆ†ç±»
- âœ… å·²éªŒè¯: {len(findings.get('verified_claims', []))} é¡¹
- âŒ å·²è¯ä¼ª: {len(findings.get('refuted_claims', []))} é¡¹
- âš ï¸ éœ€ nuanced ç†è§£: {len(findings.get('nuanced_claims', []))} é¡¹
- â“ ä¸ç¡®å®š: {len(findings.get('uncertain_claims', []))} é¡¹
"""

            # æ„å»ºè¯æ®åˆ—è¡¨
            all_sources = search_result_data.get("all_sources", [])
            evidence_text = f"## ğŸ“š è¯æ®åˆ—è¡¨ (å…± {len(all_sources)} ä¸ªä¿¡æº)\n\n"

            # å…³é”®ä¿¡æº
            key_sources = [s for s in all_sources if s.get("is_key_source", False)]
            if key_sources:
                evidence_text += "### ğŸ”‘ å…³é”®ä¿¡æº\n\n"
                for i, source in enumerate(key_sources[:5], 1):
                    credibility = source.get("source_credibility", "medium")
                    cred_emoji = "ğŸŸ¢" if credibility == "high" else "ğŸŸ¡" if credibility == "medium" else "ğŸ”´"
                    evidence_text += f"**{i}. {source.get('title', 'æœªçŸ¥æ ‡é¢˜')}**\n"
                    evidence_text += f"- æ¥æº: {source.get('source_domain', 'æœªçŸ¥')}\n"
                    evidence_text += f"- å¯ä¿¡åº¦: {cred_emoji} {credibility}\n"
                    evidence_text += f"- å…³é”®ä¿¡æ¯: {source.get('key_insight', '')[:100]}...\n\n"

            # æ™®é€šä¿¡æº
            regular_sources = [s for s in all_sources if not s.get("is_key_source", False)]
            if regular_sources:
                evidence_text += "### ğŸ“„ å…¶ä»–ä¿¡æº\n\n"
                for i, source in enumerate(regular_sources[:5], 1):
                    credibility = source.get("source_credibility", "medium")
                    cred_emoji = "ğŸŸ¢" if credibility == "high" else "ğŸŸ¡" if credibility == "medium" else "ğŸ”´"
                    evidence_text += f"**{i}. {source.get('title', 'æœªçŸ¥æ ‡é¢˜')}** ({cred_emoji} {credibility})\n"
                    evidence_text += f"   æ¥æº: {source.get('source_domain', 'æœªçŸ¥')}\n\n"

            yield reasoning_text, result_text, evidence_text, "é‰´å®šå®Œæˆ"
        else:
            result_text = "## âŒ é‰´å®šæœªå®Œæˆ\n\né‰´å®šè¿‡ç¨‹æœªèƒ½å®Œæˆï¼Œè¯·é‡è¯•ã€‚"
            yield reasoning_text, result_text, evidence_text, "é‰´å®šå¤±è´¥"

    except Exception as e:
        error_msg = f"## âŒ é”™è¯¯\n\né‰´å®šè¿‡ç¨‹å‡ºé”™: {str(e)}"
        yield reasoning_text, error_msg, evidence_text, "å‡ºé”™"


# åˆ›å»ºGradioç•Œé¢
def create_interface():
    with gr.Blocks(theme=gr.themes.Soft(), title="Aletheia - AIèˆ†æƒ…è°è¨€é‰´å®šç³»ç»Ÿ") as demo:
        # æ ‡é¢˜åŒºåŸŸ
        gr.Markdown("""
        # ğŸ” Aletheia - AIèˆ†æƒ…è°è¨€é‰´å®šç³»ç»Ÿ

        åŸºäºå¤šAgentåä½œçš„æ™ºèƒ½èˆ†æƒ…çœŸå®æ€§é‰´å®šç³»ç»Ÿï¼Œé€šè¿‡Parserã€Searchã€Verdictä¸‰ä¸ªAgentçš„æ·±åº¦åä½œï¼Œ
        ä»å¤šç»´åº¦åˆ†æé—®é¢˜ï¼Œä¸ºæ‚¨æä¾›å®¢è§‚ã€å¯ä¿¡çš„é‰´å®šç»“æœã€‚

        **ä½¿ç”¨è¯´æ˜**: åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­è¾“å…¥æ‚¨æƒ³è¦é‰´å®šçš„èˆ†æƒ…å†…å®¹ï¼Œç‚¹å‡»"å¼€å§‹é‰´å®š"æŒ‰é’®ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ†æå¹¶è¿”å›é‰´å®šç»“æœã€‚
        """)

        with gr.Row():
            with gr.Column(scale=1):
                # è¾“å…¥åŒºåŸŸ
                input_text = gr.Textbox(
                    label="è¾“å…¥èˆ†æƒ…å†…å®¹",
                    placeholder="è¯·è¾“å…¥æ‚¨æƒ³è¦é‰´å®šçš„èˆ†æƒ…å†…å®¹ï¼Œä¾‹å¦‚ï¼š\"æŸæ˜æ˜Ÿå®£å¸ƒé€€å‡ºå¨±ä¹åœˆ\"...",
                    lines=5,
                    max_lines=10
                )
                submit_btn = gr.Button("ğŸš€ å¼€å§‹é‰´å®š", variant="primary", size="lg")
                status_text = gr.Textbox(label="å½“å‰çŠ¶æ€", value="å°±ç»ª", interactive=False)

            with gr.Column(scale=2):
                # ç»“æœå±•ç¤ºåŒºåŸŸ - ä½¿ç”¨æ ‡ç­¾é¡µ
                with gr.Tabs():
                    with gr.TabItem("ğŸ“ æ¨ç†è¿‡ç¨‹"):
                        reasoning_output = gr.Markdown(
                            value='*ç‚¹å‡»"å¼€å§‹é‰´å®š"åï¼Œè¿™é‡Œå°†æ˜¾ç¤ºè¯¦ç»†çš„æ¨ç†è¿‡ç¨‹...*'
                        )

                    with gr.TabItem("ğŸ¯ é‰´å®šç»“æœ"):
                        result_output = gr.Markdown(
                            value="*é‰´å®šç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º...*"
                        )

                    with gr.TabItem("ğŸ“š è¯æ®åˆ—è¡¨"):
                        evidence_output = gr.Markdown(
                            value="*ç›¸å…³è¯æ®å°†åœ¨è¿™é‡Œæ˜¾ç¤º...*"
                        )

        # ç¤ºä¾‹
        gr.Markdown("### ğŸ’¡ ç¤ºä¾‹")
        examples = [
            ["æŸçŸ¥åç§‘æŠ€å…¬å¸CEOå®£å¸ƒè¾èŒï¼ŒåŸå› æ˜¯ä¸ªäººå¥åº·åŸå› "],
            ["æœ€æ–°ç ”ç©¶è¡¨æ˜ï¼Œæ¯å¤©å–ä¸€æ¯å’–å•¡å¯ä»¥å»¶é•¿å¯¿å‘½5å¹´"],
            ["æŸåŸå¸‚å³å°†å®æ–½æ–°çš„äº¤é€šç®¡åˆ¶æªæ–½ï¼Œé™åˆ¶å¤–åœ°è½¦è¾†è¿›å…¥"]
        ]
        gr.Examples(examples=examples, inputs=input_text)

        # ç»‘å®šäº‹ä»¶
        submit_btn.click(
            fn=verify_content_stream,
            inputs=input_text,
            outputs=[reasoning_output, result_output, evidence_output, status_text]
        )

        gr.Markdown("""
        ---
        **æŠ€æœ¯è¯´æ˜**: æœ¬ç³»ç»Ÿä½¿ç”¨DeepSeekè”ç½‘æœç´¢åŠŸèƒ½è·å–å®æ—¶ä¿¡æ¯ï¼Œé€šè¿‡å¤šAgentåä½œè¿›è¡Œæ·±åº¦åˆ†æï¼Œ
        åŒ…æ‹¬é—®é¢˜è§£æã€è¯æ®æœç´¢ã€å¤šç»´åº¦é‰´å®šä¸‰ä¸ªæ ¸å¿ƒæ­¥éª¤ã€‚
        """)

    return demo


# å¯åŠ¨åº”ç”¨
if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )
